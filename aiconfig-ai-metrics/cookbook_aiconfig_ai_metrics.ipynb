{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Config AI Metrics - Cookbook\n",
    "\n",
    "Prerequisites: `LAUNCHDARKLY_SDK_KEY`, `LAUNCHDARKLY_API_TOKEN`, AI Config created (see `aiconfig-create`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[OK] Loaded environment from /Users/ld_scarlett/Documents/Github/agent-skills/.env\n"
     ]
    }
   ],
   "source": [
    "%pip install launchdarkly-server-sdk launchdarkly-server-sdk-ai openai requests python-dotenv -q\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def find_repo_root(start_path: Path = None) -> Path:\n",
    "    current = start_path or Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / '.git').exists():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "load_dotenv(repo_root / '.env')\n",
    "print(f\"[OK] Loaded environment from {repo_root / '.env'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] SDK initialized: True\n",
      "[OK] Got config: enabled=True, model=gpt-4\n"
     ]
    }
   ],
   "source": [
    "# SDK initialization (see aiconfig-sdk for details)\n",
    "from ldclient import Context\n",
    "from ldai.client import LDAIClient, AICompletionConfigDefault\n",
    "import ldclient\n",
    "from ldclient.config import Config\n",
    "\n",
    "SDK_KEY = os.environ.get(\"LAUNCHDARKLY_SDK_KEY\")\n",
    "ldclient.set_config(Config(SDK_KEY))\n",
    "ld_client = ldclient.get()\n",
    "ai_client = LDAIClient(ld_client)\n",
    "\n",
    "print(f\"[OK] SDK initialized: {ld_client.is_initialized()}\")\n",
    "\n",
    "# Get config for testing tracker methods\n",
    "context = Context.builder(\"cookbook-test-user\").build()\n",
    "config = ai_client.completion_config(\n",
    "    \"content-assistant\",\n",
    "    context,\n",
    "    AICompletionConfigDefault(enabled=False),\n",
    "    {}\n",
    ")\n",
    "print(f\"[OK] Got config: enabled={config.enabled}, model={config.model.name if config.model else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test Tracker Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Got tracker: LDAIConfigTracker\n",
      "[OK] track_success()\n",
      "[OK] track_error()\n",
      "[OK] track_tokens(TokenUsage(total=30, input=10, output=20))\n",
      "[OK] track_duration(1.5)\n",
      "[OK] track_time_to_first_token(0.25)\n",
      "[OK] track_duration_of(fn) -> result\n",
      "[OK] Flushed metrics\n"
     ]
    }
   ],
   "source": [
    "from ldai.tracker import TokenUsage\n",
    "import time\n",
    "\n",
    "tracker = config.tracker\n",
    "print(f\"[OK] Got tracker: {type(tracker).__name__}\")\n",
    "\n",
    "# Test track_success()\n",
    "tracker.track_success()\n",
    "print(f\"[OK] track_success()\")\n",
    "\n",
    "# Test track_error()\n",
    "tracker.track_error()\n",
    "print(f\"[OK] track_error()\")\n",
    "\n",
    "# Test track_tokens() with TokenUsage\n",
    "tokens = TokenUsage(total=30, input=10, output=20)\n",
    "tracker.track_tokens(tokens)\n",
    "print(f\"[OK] track_tokens(TokenUsage(total=30, input=10, output=20))\")\n",
    "\n",
    "# Test track_duration()\n",
    "tracker.track_duration(1.5)\n",
    "print(f\"[OK] track_duration(1.5)\")\n",
    "\n",
    "# Test track_time_to_first_token()\n",
    "tracker.track_time_to_first_token(0.25)\n",
    "print(f\"[OK] track_time_to_first_token(0.25)\")\n",
    "\n",
    "# Test track_duration_of()\n",
    "def slow_fn():\n",
    "    time.sleep(0.1)\n",
    "    return \"result\"\n",
    "\n",
    "result = tracker.track_duration_of(slow_fn)\n",
    "print(f\"[OK] track_duration_of(fn) -> {result}\")\n",
    "\n",
    "ld_client.flush()\n",
    "print(f\"[OK] Flushed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## OpenAI Automatic Tracking\n",
    "From: `SKILL.md` lines 46-68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] track_openai_completion() defined\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from ldai.tracker import TokenUsage\n",
    "\n",
    "def track_openai_completion(config, prompt: str):\n",
    "    \"\"\"Track OpenAI completion with automatic metrics.\"\"\"\n",
    "    if not config.enabled:\n",
    "        return None\n",
    "\n",
    "    tracker = config.tracker\n",
    "\n",
    "    # Wrap OpenAI call - automatically captures tokens, duration, success/failure\n",
    "    response = tracker.track_openai_metrics(\n",
    "        lambda: openai.chat.completions.create(\n",
    "            model=config.model.name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": config.messages[0].content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"[OK] track_openai_completion() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing track_openai_completion ===\n",
      "[OK] Got response: Hi...\n"
     ]
    }
   ],
   "source": [
    "# Test track_openai_completion\n",
    "print(\"=== Testing track_openai_completion ===\")\n",
    "\n",
    "openai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if openai_key and config.enabled:\n",
    "    openai.api_key = openai_key\n",
    "    result = track_openai_completion(config, \"Say hello in one word\")\n",
    "    if result:\n",
    "        print(f\"[OK] Got response: {result[:50]}...\")\n",
    "        ld_client.flush()\n",
    "else:\n",
    "    print(\"[INFO] OPENAI_API_KEY not set or config disabled - skipping live test\")\n",
    "    print(\"[OK] Function defined and ready for use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Token Tracking\n",
    "From: `SKILL.md` lines 75-107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] track_anthropic_completion() defined\n"
     ]
    }
   ],
   "source": [
    "from ldai.tracker import TokenUsage\n",
    "\n",
    "def track_anthropic_completion(config, prompt: str):\n",
    "    \"\"\"Track Anthropic completion with manual metrics.\"\"\"\n",
    "    import anthropic\n",
    "    client = anthropic.Anthropic()\n",
    "\n",
    "    if not config.enabled:\n",
    "        return None\n",
    "\n",
    "    tracker = config.tracker\n",
    "\n",
    "    # Track duration of the call\n",
    "    response = tracker.track_duration_of(\n",
    "        lambda: client.messages.create(\n",
    "            model=config.model.name,\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Manually track tokens using TokenUsage object\n",
    "    if hasattr(response, 'usage'):\n",
    "        tokens = TokenUsage(\n",
    "            total=response.usage.input_tokens + response.usage.output_tokens,\n",
    "            input=response.usage.input_tokens,\n",
    "            output=response.usage.output_tokens\n",
    "        )\n",
    "        tracker.track_tokens(tokens)\n",
    "\n",
    "    tracker.track_success()\n",
    "    return response.content[0].text\n",
    "\n",
    "print(\"[OK] track_anthropic_completion() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Streaming Metrics\n",
    "From: `SKILL.md` lines 112-156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] track_streaming_completion() defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ldai.tracker import TokenUsage\n",
    "\n",
    "def track_streaming_completion(config, prompt: str):\n",
    "    \"\"\"Track metrics for streaming responses.\"\"\"\n",
    "    import openai\n",
    "\n",
    "    if not config.enabled:\n",
    "        return None\n",
    "\n",
    "    tracker = config.tracker\n",
    "    start_time = time.time()\n",
    "    first_token_time = None\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=config.model.name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in stream:\n",
    "        if first_token_time is None and chunk.choices[0].delta.content:\n",
    "            first_token_time = time.time()\n",
    "            tracker.track_time_to_first_token(first_token_time - start_time)\n",
    "\n",
    "        if chunk.choices[0].delta.content:\n",
    "            response_text += chunk.choices[0].delta.content\n",
    "\n",
    "    # Track final metrics\n",
    "    tracker.track_duration(time.time() - start_time)\n",
    "    tracker.track_success()\n",
    "\n",
    "    # Estimate tokens (or use tiktoken for accuracy)\n",
    "    estimated_input = len(prompt.split()) * 2\n",
    "    estimated_output = len(response_text.split()) * 2\n",
    "    tokens = TokenUsage(\n",
    "        total=estimated_input + estimated_output,\n",
    "        input=estimated_input,\n",
    "        output=estimated_output\n",
    "    )\n",
    "    tracker.track_tokens(tokens)\n",
    "\n",
    "    return response_text\n",
    "\n",
    "print(\"[OK] track_streaming_completion() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieving Metrics via API\n",
    "From: `SKILL.md` lines 187-225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] get_ai_metrics() defined\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_ai_metrics(project_key: str, config_key: str, hours: int = 24):\n",
    "    \"\"\"Get AI metrics for the last N hours.\"\"\"\n",
    "    API_TOKEN = os.environ.get(\"LAUNCHDARKLY_API_TOKEN\")\n",
    "\n",
    "    now = int(time.time())\n",
    "    start = now - (hours * 3600)\n",
    "\n",
    "    url = f\"https://app.launchdarkly.com/api/v2/projects/{project_key}/ai-configs/{config_key}/metrics\"\n",
    "\n",
    "    params = {\n",
    "        \"from\": start,\n",
    "        \"to\": now,\n",
    "        \"env\": \"production\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": API_TOKEN,\n",
    "        \"LD-API-Version\": \"beta\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        metrics = response.json()\n",
    "        print(f\"[INFO] Metrics for {config_key} (last {hours} hours):\")\n",
    "        print(f\"   Total Tokens: {metrics.get('totalTokens', 0):,}\")\n",
    "        print(f\"   Total Cost: ${metrics.get('totalCost', 0):.4f}\")\n",
    "        print(f\"   Request Count: {metrics.get('requestCount', 0):,}\")\n",
    "        print(f\"   Avg Latency: {metrics.get('avgLatency', 0):.2f}s\")\n",
    "        print(f\"   Success Rate: {metrics.get('successRate', 0):.1f}%\")\n",
    "        return metrics\n",
    "    else:\n",
    "        print(f\"[ERROR] Failed to get metrics: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "print(\"[OK] get_ai_metrics() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing get_ai_metrics ===\n",
      "[INFO] Metrics for content-assistant (last 24 hours):\n",
      "   Total Tokens: 0\n",
      "   Total Cost: $0.0000\n",
      "   Request Count: 0\n",
      "   Avg Latency: 0.00s\n",
      "   Success Rate: 0.0%\n",
      "[OK] Metrics retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "# Test get_ai_metrics\n",
    "print(\"=== Testing get_ai_metrics ===\")\n",
    "metrics = get_ai_metrics(\"support-ai\", \"content-assistant\", hours=24)\n",
    "if metrics:\n",
    "    print(\"[OK] Metrics retrieved successfully\")\n",
    "else:\n",
    "    print(\"[INFO] No metrics available (endpoint may not be active yet)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}