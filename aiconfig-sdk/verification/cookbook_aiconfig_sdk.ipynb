{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Config SDK - Cookbook\n",
    "\n",
    "This cookbook tests all code from `aiconfig-sdk/SKILL.md` for consuming AI Configs in your Python application.\n",
    "\n",
    "## Prerequisites\n",
    "- `LAUNCHDARKLY_SDK_KEY`: SDK key from your project (in `.env` at repo root)\n",
    "- AI Config created (run `cookbook_aiconfig_create.ipynb` first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[OK] Loaded environment from: /Users/ld_scarlett/Documents/Github/agent-skills/.env\n"
     ]
    }
   ],
   "source": [
    "# Install and load environment\n",
    "%pip install launchdarkly-server-sdk launchdarkly-server-sdk-ai python-dotenv -q\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def find_repo_root(start_path: Path = None) -> Path:\n",
    "    \"\"\"Find the repository root by looking for .git directory.\"\"\"\n",
    "    current = start_path or Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / '.git').exists():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "# Load .env from repository root\n",
    "repo_root = find_repo_root()\n",
    "env_path = repo_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "print(f\"[OK] Loaded environment from: {env_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building User Context\n",
    "From: `SKILL.md` lines 79-96\n",
    "\n",
    "Note: This is a pure utility function with no SDK dependency, so we define it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] build_context defined\n"
     ]
    }
   ],
   "source": [
    "from ldclient import Context\n",
    "\n",
    "def build_context(user_id: str, **attributes):\n",
    "    \"\"\"Build LaunchDarkly context for targeting.\"\"\"\n",
    "    builder = Context.builder(user_id)\n",
    "    for key, value in attributes.items():\n",
    "        builder.set(key, value)\n",
    "    return builder.build()\n",
    "\n",
    "# Basic context\n",
    "context = build_context(\"user-123\")\n",
    "\n",
    "# Context with attributes for targeting\n",
    "context = build_context(\n",
    "    \"user-123\",\n",
    "    subscription_tier=\"premium\",\n",
    "    region=\"us-west\"\n",
    ")\n",
    "print(f\"[OK] build_context defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic SDK Setup\n",
    "From: `SKILL.md` lines 52-75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] SDK initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ldclient\n",
    "from ldclient import Context\n",
    "from ldclient.config import Config\n",
    "from ldai.client import LDAIClient\n",
    "\n",
    "def initialize_launchdarkly(sdk_key: str):\n",
    "    \"\"\"Initialize LaunchDarkly SDK.\"\"\"\n",
    "    config = Config(sdk_key)\n",
    "    ldclient.set_config(config)\n",
    "\n",
    "    ld_client = ldclient.get()\n",
    "    ai_client = LDAIClient(ld_client)\n",
    "\n",
    "    if not ld_client.is_initialized():\n",
    "        raise Exception(\"LaunchDarkly client failed to initialize\")\n",
    "\n",
    "    print(f\"[OK] SDK initialized\")\n",
    "    return ld_client, ai_client\n",
    "\n",
    "SDK_KEY = os.environ.get(\"LAUNCHDARKLY_SDK_KEY\")\n",
    "ld_client, ai_client = initialize_launchdarkly(SDK_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: initialize_launchdarkly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Initialized: True\n",
      "LD Client type: LDClient\n",
      "AI Client type: LDAIClient\n"
     ]
    }
   ],
   "source": [
    "# Verify SDK initialized properly\n",
    "print(f\"SDK Initialized: {ld_client.is_initialized()}\")\n",
    "print(f\"LD Client type: {type(ld_client).__name__}\")\n",
    "print(f\"AI Client type: {type(ai_client).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Consuming Completion Configs\n",
    "From: `SKILL.md` lines 100-124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Config 'content-assistant' loaded - model: gpt-4\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from ldai.client import AICompletionConfigDefault, ModelConfig, LDMessage, ProviderConfig\n",
    "\n",
    "# Register fallback configs for specific config keys that need fallbacks\n",
    "fallback_configs: Dict[str, AICompletionConfigDefault] = {}\n",
    "\n",
    "def get_completion_config(ai_client, config_key: str, context, variables: dict = None):\n",
    "    \"\"\"Get completion-mode AI Config with optional fallback.\"\"\"\n",
    "    fallback = fallback_configs.get(config_key, AICompletionConfigDefault(enabled=False))\n",
    "    config = ai_client.completion_config(config_key, context, fallback, variables or {})\n",
    "    return config\n",
    "\n",
    "# Test with config created by aiconfig-create cookbook\n",
    "context = build_context(\"user-123\", tier=\"premium\")\n",
    "config = get_completion_config(ai_client, \"content-assistant\", context)\n",
    "\n",
    "if config.enabled:\n",
    "    model = config.model.name\n",
    "    messages = config.messages\n",
    "    tracker = config.tracker\n",
    "    print(f\"[OK] Config 'content-assistant' loaded - model: {model}\")\n",
    "else:\n",
    "    print(f\"[WARNING] Config 'content-assistant' is disabled or not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: Completion Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing completion config: content-assistant ===\n",
      "\n",
      "==================================================\n",
      "content-assistant:\n",
      "==================================================\n",
      "  Type: AICompletionConfig\n",
      "  Enabled: True\n",
      "  Model: gpt-4\n",
      "  Provider: \n",
      "  Messages: 2\n",
      "  Tracker: LDAIConfigTracker\n",
      "==================================================\n",
      "\n",
      "[OK] Successfully loaded config from LaunchDarkly\n"
     ]
    }
   ],
   "source": [
    "# Helper to print config details\n",
    "def print_config(config, name=\"Config\"):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  Type: {type(config).__name__}\")\n",
    "    print(f\"  Enabled: {config.enabled}\")\n",
    "    if hasattr(config, 'model') and config.model:\n",
    "        print(f\"  Model: {config.model.name}\")\n",
    "    if hasattr(config, 'provider') and config.provider:\n",
    "        print(f\"  Provider: {config.provider.name}\")\n",
    "    if hasattr(config, 'messages') and config.messages:\n",
    "        print(f\"  Messages: {len(config.messages)}\")\n",
    "    if hasattr(config, 'instructions') and config.instructions:\n",
    "        display = f\"{config.instructions[:100]}...\" if len(config.instructions) > 100 else config.instructions\n",
    "        print(f\"  Instructions: {display}\")\n",
    "    if hasattr(config, 'tracker') and config.tracker:\n",
    "        print(f\"  Tracker: {type(config.tracker).__name__}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# Test completion config: content-assistant\n",
    "print(\"=== Testing completion config: content-assistant ===\")\n",
    "test_context = build_context(\"verify-user\", brand=\"TestBrand\")\n",
    "completion_config = get_completion_config(ai_client, \"content-assistant\", test_context, {\"brand\": \"TestBrand\", \"content_request\": \"Write a tagline\"})\n",
    "print_config(completion_config, \"content-assistant\")\n",
    "\n",
    "# Verify config is enabled (loaded from LaunchDarkly)\n",
    "assert completion_config.enabled, \"Expected config to be enabled!\"\n",
    "print(f\"\\n[OK] Successfully loaded config from LaunchDarkly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Consuming Agent Configs\n",
    "From: `SKILL.md` lines 128-151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Agent config 'support-agent' loaded - model: gpt-4\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from ldai.client import AIAgentConfigDefault\n",
    "\n",
    "# Register fallback configs for specific agent config keys that need fallbacks\n",
    "agent_fallback_configs: Dict[str, AIAgentConfigDefault] = {}\n",
    "\n",
    "def get_agent_config(ai_client, config_key: str, context, variables: dict = None):\n",
    "    \"\"\"Get agent-mode AI Config with optional fallback.\"\"\"\n",
    "    fallback = agent_fallback_configs.get(config_key, AIAgentConfigDefault(enabled=False))\n",
    "    config = ai_client.agent_config(config_key, context, fallback, variables or {})\n",
    "    return config\n",
    "\n",
    "# Test with agent config created by aiconfig-create cookbook\n",
    "context = build_context(\"user-123\")\n",
    "config = get_agent_config(ai_client, \"support-agent\", context)\n",
    "\n",
    "if config.enabled:\n",
    "    instructions = config.instructions\n",
    "    model_name = config.model.name\n",
    "    tracker = config.tracker\n",
    "    print(f\"[OK] Agent config 'support-agent' loaded - model: {model_name}\")\n",
    "else:\n",
    "    print(f\"[WARNING] Agent config 'support-agent' is disabled or not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: get_agent_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing agent config: support-agent ===\n",
      "\n",
      "==================================================\n",
      "support-agent:\n",
      "==================================================\n",
      "  Type: AIAgentConfig\n",
      "  Enabled: True\n",
      "  Model: gpt-4\n",
      "  Provider: \n",
      "  Instructions: You are a helpful customer support agent.\n",
      "\n",
      "Your responsibilities:\n",
      "- Answer customer questions\n",
      "- Reso...\n",
      "  Tracker: LDAIConfigTracker\n",
      "==================================================\n",
      "\n",
      "[OK] Successfully loaded agent config from LaunchDarkly\n"
     ]
    }
   ],
   "source": [
    "# Test agent config: support-agent\n",
    "print(\"=== Testing agent config: support-agent ===\")\n",
    "test_context = build_context(\"agent-verify-user\")\n",
    "agent_config = get_agent_config(\n",
    "    ai_client,\n",
    "    \"support-agent\",\n",
    "    test_context,\n",
    "    {\"company_name\": \"TestCorp\", \"support_priority\": \"high\"}\n",
    ")\n",
    "\n",
    "print_config(agent_config, \"support-agent\")\n",
    "\n",
    "# Verify config is enabled\n",
    "assert agent_config.enabled, \"Expected config to be enabled!\"\n",
    "print(f\"\\n[OK] Successfully loaded agent config from LaunchDarkly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fresh Configs Per Request\n",
    "From: `SKILL.md` lines 157-174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicAIClient:\n",
    "    \"\"\"Fetch fresh config for every request - never cache configs.\"\"\"\n",
    "    def __init__(self, ai_client, config_key: str):\n",
    "        self.ai_client = ai_client\n",
    "        self.config_key = config_key\n",
    "\n",
    "    def generate(self, prompt: str, user_id: str, **user_attributes):\n",
    "        \"\"\"Get fresh config for each request.\"\"\"\n",
    "        context = build_context(user_id, **user_attributes)\n",
    "        config = get_completion_config(self.ai_client, self.config_key, context)\n",
    "        return config  # Process with this config\n",
    "\n",
    "# Test with content-assistant config\n",
    "client = DynamicAIClient(ai_client, \"content-assistant\")\n",
    "config1 = client.generate(\"Hello\", \"user-123\", tier=\"free\")\n",
    "config2 = client.generate(\"Hello\", \"user-456\", tier=\"premium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: DynamicAIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicAIClient verification:\n",
      "  Config key: content-assistant\n",
      "  User 'user-free' config enabled: True\n",
      "  User 'user-premium' config enabled: True\n",
      "  Both configs are different objects: True\n",
      "[OK] DynamicAIClient verified\n"
     ]
    }
   ],
   "source": [
    "# Test DynamicAIClient\n",
    "dynamic_client = DynamicAIClient(ai_client, \"content-assistant\")\n",
    "\n",
    "# Different users getting fresh configs\n",
    "config1 = dynamic_client.generate(\"Hello\", \"user-free\", tier=\"free\")\n",
    "config2 = dynamic_client.generate(\"Hello\", \"user-premium\", tier=\"premium\")\n",
    "\n",
    "print(\"DynamicAIClient verification:\")\n",
    "print(f\"  Config key: content-assistant\")\n",
    "print(f\"  User 'user-free' config enabled: {config1.enabled}\")\n",
    "print(f\"  User 'user-premium' config enabled: {config2.enabled}\")\n",
    "print(f\"  Both configs are different objects: {config1 is not config2}\")\n",
    "print(f\"[OK] DynamicAIClient verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Handling Multiple Configs\n",
    "From: `SKILL.md` lines 178-211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated summary: Summary of: This is a sample document with important informati...\n",
      "[OK] Translated summary: Translated: Summary of: This is a sample document with importa...\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(text: str, config) -> str:\n",
    "    \"\"\"Generate summary using the config's model and messages.\"\"\"\n",
    "    # Use config.model.name, config.messages, config.tracker\n",
    "    # Call your LLM provider and return summary\n",
    "    return f\"Summary of: {text[:50]}...\"\n",
    "\n",
    "def translate_text(text: str, config) -> str:\n",
    "    \"\"\"Translate text using the config's model and messages.\"\"\"\n",
    "    # Use config.model.name, config.messages, config.tracker\n",
    "    # Call your LLM provider and return translation\n",
    "    return f\"Translated: {text[:50]}...\"\n",
    "\n",
    "def get_multiple_configs(ai_client, user_id: str):\n",
    "    \"\"\"Get multiple AI Configs for different purposes.\"\"\"\n",
    "    context = build_context(user_id)\n",
    "\n",
    "    configs = {\n",
    "        \"summarizer\": get_completion_config(ai_client, \"content-assistant\", context),\n",
    "        \"translator\": get_completion_config(ai_client, \"content-assistant\", context),\n",
    "        \"analyzer\": get_agent_config(ai_client, \"support-agent\", context)\n",
    "    }\n",
    "    return configs\n",
    "\n",
    "# Use configs in sequence - summarize then translate the summary\n",
    "text = \"This is a sample document with important information about the product.\"\n",
    "configs = get_multiple_configs(ai_client, \"user-123\")\n",
    "\n",
    "if configs[\"summarizer\"].enabled:\n",
    "    summary = generate_summary(text, configs[\"summarizer\"])\n",
    "    print(f\"[OK] Generated summary: {summary}\")\n",
    "\n",
    "    # Pass summary to translator\n",
    "    if configs[\"translator\"].enabled:\n",
    "        translation = translate_text(summary, configs[\"translator\"])\n",
    "        print(f\"[OK] Translated summary: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: get_multiple_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing get_multiple_configs ===\n",
      "Configs retrieved: ['summarizer', 'translator', 'analyzer']\n",
      "  [OK] summarizer: model=gpt-4\n",
      "  [OK] translator: model=gpt-4\n",
      "  [OK] analyzer: model=gpt-4\n",
      "[OK] Multiple configs pattern verified\n"
     ]
    }
   ],
   "source": [
    "# Test get_multiple_configs\n",
    "print(\"=== Testing get_multiple_configs ===\")\n",
    "multi_configs = get_multiple_configs(ai_client, \"multi-config-user\")\n",
    "\n",
    "print(f\"Configs retrieved: {list(multi_configs.keys())}\")\n",
    "for name, cfg in multi_configs.items():\n",
    "    status = \"[OK]\" if cfg.enabled else \"[DISABLED]\"\n",
    "    model = cfg.model.name if cfg.model else 'N/A'\n",
    "    print(f\"  {status} {name}: model={model}\")\n",
    "print(f\"[OK] Multiple configs pattern verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Variable Substitution\n",
    "From: `SKILL.md` lines 215-238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Variable substitution working\n",
      "Instructions preview: You are a helpful customer support agent.\n",
      "\n",
      "Your responsibilities:\n",
      "- Answer customer questions\n",
      "- Resolve issues efficiently\n",
      "- Maintain a friendly tone\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# In LaunchDarkly, your instruction might be:\n",
    "# \"You are a {{role}} assistant for {{company}}. Focus on {{focus_area}}.\"\n",
    "\n",
    "context = build_context(\"user-123\")\n",
    "\n",
    "# Provide variable values at runtime\n",
    "config = get_agent_config(\n",
    "    ai_client,\n",
    "    \"support-agent\",\n",
    "    context,\n",
    "    variables={\n",
    "        \"company_name\": \"TechCorp\",\n",
    "        \"support_priority\": \"billing issues\"\n",
    "    }\n",
    ")\n",
    "\n",
    "if config.enabled:\n",
    "    # Instructions are populated with variable values\n",
    "    print(f\"[OK] Variable substitution working\")\n",
    "    print(f\"Instructions preview: {config.instructions[:150]}...\")\n",
    "else:\n",
    "    print(f\"[WARNING] Config is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify: Variable Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable substitution verification:\n",
      "  Config key: support-agent\n",
      "  Variables passed: company_name=AcmeCorp, support_priority=high\n",
      "  Config enabled: True\n",
      "  Instructions (first 200 chars): You are a helpful customer support agent.\n",
      "\n",
      "Your responsibilities:\n",
      "- Answer customer questions\n",
      "- Resolve issues efficiently\n",
      "- Maintain a friendly tone\n",
      "\n",
      "Company: AcmeCorp\n",
      "Priority: high...\n",
      "[OK] Variable substitution verified\n"
     ]
    }
   ],
   "source": [
    "# Additional verification with support-agent config\n",
    "context = build_context(\"variable-test-user\")\n",
    "\n",
    "config_with_vars = get_agent_config(\n",
    "    ai_client,\n",
    "    \"support-agent\",\n",
    "    context,\n",
    "    variables={\n",
    "        \"company_name\": \"AcmeCorp\",\n",
    "        \"support_priority\": \"high\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Variable substitution verification:\")\n",
    "print(f\"  Config key: support-agent\")\n",
    "print(f\"  Variables passed: company_name=AcmeCorp, support_priority=high\")\n",
    "print(f\"  Config enabled: {config_with_vars.enabled}\")\n",
    "if config_with_vars.enabled and config_with_vars.instructions:\n",
    "    print(f\"  Instructions (first 200 chars): {config_with_vars.instructions[:200]}...\")\n",
    "print(f\"[OK] Variable substitution verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Error Handling\n",
    "From: `SKILL.md` lines 242-266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] process_with_config() defined\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def call_llm(model_name: str, messages, prompt: str) -> str:\n",
    "    \"\"\"Stub for LLM call - replace with actual implementation.\"\"\"\n",
    "    return f\"Response from {model_name} for: {prompt[:30]}...\"\n",
    "\n",
    "def process_with_config(ai_client, config_key: str, user_id: str, prompt: str):\n",
    "    \"\"\"Process request with AI Config and proper error handling.\"\"\"\n",
    "    context = build_context(user_id)\n",
    "    config = get_completion_config(ai_client, config_key, context)\n",
    "\n",
    "    if not config.enabled:\n",
    "        logger.warning(f\"Config '{config_key}' is disabled or not found\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Use the config to make your LLM call\n",
    "        result = call_llm(config.model.name, config.messages, prompt)\n",
    "        config.tracker.track_success()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LLM call failed: {e}\")\n",
    "        config.tracker.track_error()\n",
    "        return None\n",
    "\n",
    "print(\"[OK] process_with_config() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config 'nonexistent-config' is disabled or not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing process_with_config ===\n",
      "[OK] Got result: Response from gpt-4 for: Write a tagline...\n",
      "[OK] Gracefully handled nonexistent config\n"
     ]
    }
   ],
   "source": [
    "# Test error handling\n",
    "print(\"=== Testing process_with_config ===\")\n",
    "\n",
    "# Test with real config\n",
    "result = process_with_config(ai_client, \"content-assistant\", \"test-user\", \"Write a tagline\")\n",
    "if result:\n",
    "    print(f\"[OK] Got result: {result}\")\n",
    "else:\n",
    "    print(\"[WARNING] No result returned\")\n",
    "\n",
    "# Test with nonexistent config (should handle gracefully)\n",
    "result = process_with_config(ai_client, \"nonexistent-config\", \"test-user\", \"Hello\")\n",
    "if result is None:\n",
    "    print(f\"[OK] Gracefully handled nonexistent config\")\n",
    "else:\n",
    "    print(f\"[INFO] Got result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
